{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfeb7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import AerSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HadamardTransform:\n",
    "    def __init__(self):\n",
    "        self.backend = AerSimulator(method=\"statevector\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "\n",
    "        # ensures cpu usage\n",
    "        if x.is_cuda:\n",
    "            x = x.cpu()\n",
    "\n",
    "        # flatten image for qiskit\n",
    "        img_flat = x.flatten().detach().numpy().astype(np.float64)\n",
    "        len = img_flat.size\n",
    "\n",
    "        # find number of qubits\n",
    "        n_qubits = int(np.ceil(np.log2(len)))\n",
    "        N = np.pow(2, n_qubits)\n",
    "\n",
    "        # pad\n",
    "        state_vector = np.zeros(N, dtype=np.float64)\n",
    "        state_vector[:len] = img_flat\n",
    "\n",
    "        # normalize constant\n",
    "        norm = np.linalg.norm(state_vector)\n",
    "\n",
    "        # cover edge case of fully black image\n",
    "        if norm == 0:\n",
    "            return torch.zeros_like(x)\n",
    "        \n",
    "        # normalize the state vector\n",
    "        state_vector = state_vector / norm\n",
    "\n",
    "        # circuit initialized with flattened image and hadamard on all rows\n",
    "        qc = QuantumCircuit(n_qubits)\n",
    "        qc.initialize(state_vector, qc.qubits)\n",
    "        qc.h(range(n_qubits))\n",
    "        qc.save_statevector()\n",
    "\n",
    "        # create simulatible circuit\n",
    "        tqc = transpile(qc, self.backend)\n",
    "        result = self.backend.run(tqc).result()\n",
    "        state = np.asarray(result.get_statevector(tqc))\n",
    "\n",
    "        # take first 784 entries back, convert to real features\n",
    "        y = np.real(state[:len]) * norm\n",
    "        y = y.reshape(x.shape).astype(np.float32)\n",
    "\n",
    "        return torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c37408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download format\n",
    "# turns MNIST images to PyTorch tensors and normalizes between [-1,1] centered at 0\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "    HadamardTransform()\n",
    "])\n",
    "\n",
    "# download data\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,         # each epoch is 128 samples\n",
    "    shuffle=True            # randomize after each training epoch\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=256,         # each epoch is 256 samples\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# test shapes of pytorch datasets\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c688f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# create model, loss, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Muon(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcdb68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13176fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results and accuracy\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
